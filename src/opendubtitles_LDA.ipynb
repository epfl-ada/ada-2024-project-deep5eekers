{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetInfo' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m ds \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuggingface:open_subtitles/fr-hy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\xrist\\anaconda3\\envs\\ada\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:176\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[1;32mc:\\Users\\xrist\\anaconda3\\envs\\ada\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:655\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;129m@tfds_logging\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m    522\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    537\u001b[0m ):\n\u001b[0;32m    538\u001b[0m   \u001b[38;5;66;03m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03m  `tfds.load` is a convenience method that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;124;03m      Split-specific information is available in `ds_info.splits`.\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# fmt: skip\u001b[39;00m\n\u001b[1;32m--> 655\u001b[0m   dbuilder \u001b[38;5;241m=\u001b[39m _fetch_builder(\n\u001b[0;32m    656\u001b[0m       name,\n\u001b[0;32m    657\u001b[0m       data_dir,\n\u001b[0;32m    658\u001b[0m       builder_kwargs,\n\u001b[0;32m    659\u001b[0m       try_gcs,\n\u001b[0;32m    660\u001b[0m   )\n\u001b[0;32m    661\u001b[0m   _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)\n\u001b[0;32m    663\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m as_dataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\xrist\\anaconda3\\envs\\ada\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:497\u001b[0m, in \u001b[0;36m_fetch_builder\u001b[1;34m(name, data_dir, builder_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builder_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m   builder_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder(name, data_dir\u001b[38;5;241m=\u001b[39mdata_dir, try_gcs\u001b[38;5;241m=\u001b[39mtry_gcs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuilder_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\xrist\\anaconda3\\envs\\ada\\Lib\\contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\xrist\\anaconda3\\envs\\ada\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:176\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[1;32mc:\\Users\\xrist\\anaconda3\\envs\\ada\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:191\u001b[0m, in \u001b[0;36mbuilder\u001b[1;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mnamespace:\n\u001b[0;32m    190\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mnamespace \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuggingface\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m huggingface_dataset_builder\u001b[38;5;241m.\u001b[39mbuilder(\n\u001b[0;32m    192\u001b[0m         name\u001b[38;5;241m=\u001b[39mname\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuilder_kwargs)\n\u001b[0;32m    193\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    194\u001b[0m       visibility\u001b[38;5;241m.\u001b[39mDatasetType\u001b[38;5;241m.\u001b[39mCOMMUNITY_PUBLIC\u001b[38;5;241m.\u001b[39mis_available()\n\u001b[0;32m    195\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m community\u001b[38;5;241m.\u001b[39mcommunity_register()\u001b[38;5;241m.\u001b[39mhas_namespace(name\u001b[38;5;241m.\u001b[39mnamespace)\n\u001b[0;32m    196\u001b[0m   ):\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m community\u001b[38;5;241m.\u001b[39mcommunity_register()\u001b[38;5;241m.\u001b[39mbuilder(name\u001b[38;5;241m=\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuilder_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\xrist\\anaconda3\\envs\\ada\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builders\\huggingface_dataset_builder.py:520\u001b[0m, in \u001b[0;36mbuilder\u001b[1;34m(name, config, **builder_kwargs)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuilder\u001b[39m(\n\u001b[0;32m    518\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m, config: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuilder_kwargs\n\u001b[0;32m    519\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HuggingfaceDatasetBuilder:\n\u001b[1;32m--> 520\u001b[0m   hf_repo_id \u001b[38;5;241m=\u001b[39m huggingface_utils\u001b[38;5;241m.\u001b[39mto_huggingface_name(name)\n\u001b[0;32m    521\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HuggingfaceDatasetBuilder(\n\u001b[0;32m    522\u001b[0m       hf_repo_id\u001b[38;5;241m=\u001b[39mhf_repo_id, hf_config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuilder_kwargs\n\u001b[0;32m    523\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\xrist\\anaconda3\\envs\\ada\\Lib\\site-packages\\tensorflow_datasets\\core\\utils\\huggingface_utils.py:142\u001b[0m, in \u001b[0;36mto_huggingface_name\u001b[1;34m(tfds_dataset_name)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts TFDS dataset name to a Huggingface compatible dataset name.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03mAs TFDS doesn't support case-sensitive names, we list all HF datasets and pick\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m  existing Huggingface dataset.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hf_dataset_name \u001b[38;5;129;01min\u001b[39;00m huggingface_hub\u001b[38;5;241m.\u001b[39mlist_datasets():\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m--> 142\u001b[0m       conversion_utils\u001b[38;5;241m.\u001b[39mto_tfds_name(hf_dataset_name)\n\u001b[0;32m    143\u001b[0m       \u001b[38;5;241m==\u001b[39m tfds_dataset_name\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    144\u001b[0m   ):\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hf_dataset_name\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m registered\u001b[38;5;241m.\u001b[39mDatasetNotFoundError(\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtfds_dataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not listed in Huggingface datasets.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    148\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\xrist\\anaconda3\\envs\\ada\\Lib\\site-packages\\tensorflow_datasets\\core\\utils\\conversion_utils.py:49\u001b[0m, in \u001b[0;36mto_tfds_name\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_tfds_name\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a name to a TFDS compatible dataset name.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m  Huggingface names can contain characters that are not supported in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    names).\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m   name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m py_utils\u001b[38;5;241m.\u001b[39mmake_valid_name(name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DatasetInfo' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "ds = tfds.load('huggingface:open_subtitles/fr-hy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
